{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network with Optuna\n",
        "\n",
        "This notebook trains a fully-connected neural network on the NN feature matrices, tuning depth, width, dropout, optimizer, and learning rate via Optuna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (3895, 19), Val shape: (383, 19), Test shape: (479, 19)\n",
            "Detected 5 classes\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "DATA_DIR = Path(\"/Users/aaryan/Desktop/ML_multi_class/preprocessed_csv\")\n",
        "OUTPUT_DIR = Path(\"/Users/aaryan/Desktop/ML_multi_class\")\n",
        "\n",
        "X_train = pd.read_csv(DATA_DIR / \"X_train_nn_smote.csv\").to_numpy(dtype=np.float32)\n",
        "y_train = pd.read_csv(DATA_DIR / \"y_train_smote.csv\").squeeze().to_numpy()\n",
        "\n",
        "X_val = pd.read_csv(DATA_DIR / \"X_val_nn.csv\").to_numpy(dtype=np.float32)\n",
        "y_val = pd.read_csv(DATA_DIR / \"y_val.csv\").squeeze().to_numpy()\n",
        "\n",
        "X_test = pd.read_csv(DATA_DIR / \"X_test_nn.csv\").to_numpy(dtype=np.float32)\n",
        "test_ids = pd.read_csv(DATA_DIR / \"test_ids.csv\")\n",
        "\n",
        "label_map = pd.read_csv(DATA_DIR / \"label_encoder_mapping.csv\")\n",
        "encoded_to_cluster = dict(zip(label_map[\"encoded_value\"], label_map[\"cluster_name\"]))\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(np.unique(np.concatenate([y_train, y_val])))\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
        "print(f\"Detected {num_classes} classes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(trial: optuna.Trial) -> keras.Model:\n",
        "    n_hidden = trial.suggest_int(\"n_hidden\", 1, 4)\n",
        "    hidden_units = trial.suggest_int(\"hidden_units\", 128, 768, step=64)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"adamw\"])\n",
        "\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    x = inputs\n",
        "    for _ in range(n_hidden):\n",
        "        x = keras.layers.Dense(hidden_units, activation=\"relu\")(x)\n",
        "        if dropout > 0:\n",
        "            x = keras.layers.Dropout(dropout)(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    if optimizer_name == \"adam\":\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    elif optimizer_name == \"adamw\":\n",
        "        optimizer = keras.optimizers.AdamW(learning_rate=lr)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def objective(trial: optuna.Trial) -> float:\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "    epochs = trial.suggest_int(\"epochs\", 20, 80, step=10)\n",
        "\n",
        "    model = build_model(trial)\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_f1_macro\",\n",
        "        mode=\"max\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "    )\n",
        "\n",
        "    class F1Callback(keras.callbacks.Callback):\n",
        "        def __init__(self):\n",
        "            self.val_f1 = []\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            preds = np.argmax(self.model.predict(X_val, verbose=0), axis=1)\n",
        "            f1 = f1_score(y_val, preds, average=\"macro\")\n",
        "            logs = logs or {}\n",
        "            logs[\"val_f1_macro\"] = f1\n",
        "            self.val_f1.append(f1)\n",
        "\n",
        "    f1_callback = F1Callback()\n",
        "\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[f1_callback, early_stop],\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    best_f1 = max(f1_callback.val_f1)\n",
        "    preds = np.argmax(model.predict(X_val, verbose=0), axis=1)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    trial.set_user_attr(\"accuracy\", acc)\n",
        "    return best_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-27 14:21:02,238] A new study created in memory with name: nn_macro_f1\n",
            "[I 2025-11-27 14:21:06,917] Trial 0 finished with value: 0.5698211115005373 and parameters: {'batch_size': 128, 'epochs': 70, 'n_hidden': 2, 'hidden_units': 448, 'dropout': 0.32713306579619544, 'lr': 0.0005165722488223508, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.5698211115005373.\n",
            "[I 2025-11-27 14:21:19,882] Trial 1 finished with value: 0.5972415041404588 and parameters: {'batch_size': 64, 'epochs': 30, 'n_hidden': 4, 'hidden_units': 576, 'dropout': 0.1781231467477145, 'lr': 0.00017837121041514768, 'optimizer': 'adam'}. Best is trial 1 with value: 0.5972415041404588.\n",
            "[I 2025-11-27 14:21:29,414] Trial 2 finished with value: 0.6229240737732653 and parameters: {'batch_size': 32, 'epochs': 70, 'n_hidden': 4, 'hidden_units': 128, 'dropout': 0.47671295725378376, 'lr': 0.0002714935065113107, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:21:33,082] Trial 3 finished with value: 0.5463280137869495 and parameters: {'batch_size': 32, 'epochs': 60, 'n_hidden': 1, 'hidden_units': 704, 'dropout': 0.16163942113733537, 'lr': 0.0018454439303925018, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:21:36,592] Trial 4 finished with value: 0.5801855989100083 and parameters: {'batch_size': 128, 'epochs': 50, 'n_hidden': 2, 'hidden_units': 256, 'dropout': 0.04236371939393113, 'lr': 0.002004696502663502, 'optimizer': 'adam'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:21:57,218] Trial 5 finished with value: 0.5960375200477265 and parameters: {'batch_size': 32, 'epochs': 40, 'n_hidden': 3, 'hidden_units': 640, 'dropout': 0.4814684653591327, 'lr': 0.0002057179363045786, 'optimizer': 'adam'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:06,900] Trial 6 finished with value: 0.6158423148156829 and parameters: {'batch_size': 64, 'epochs': 70, 'n_hidden': 4, 'hidden_units': 128, 'dropout': 0.32406231934884183, 'lr': 0.0005986853497401002, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:15,929] Trial 7 finished with value: 0.5825268601603277 and parameters: {'batch_size': 64, 'epochs': 40, 'n_hidden': 4, 'hidden_units': 192, 'dropout': 0.21576418576206852, 'lr': 0.0001022404061886794, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:25,917] Trial 8 finished with value: 0.5912530968763507 and parameters: {'batch_size': 32, 'epochs': 30, 'n_hidden': 3, 'hidden_units': 576, 'dropout': 0.18798079775699467, 'lr': 0.0009042884666083351, 'optimizer': 'adam'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:29,703] Trial 9 finished with value: 0.5930729342294918 and parameters: {'batch_size': 128, 'epochs': 70, 'n_hidden': 3, 'hidden_units': 192, 'dropout': 0.11102141814307354, 'lr': 0.004140195158274687, 'optimizer': 'adam'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:36,776] Trial 10 finished with value: 0.537167773924506 and parameters: {'batch_size': 32, 'epochs': 80, 'n_hidden': 1, 'hidden_units': 384, 'dropout': 0.49691072182709595, 'lr': 0.00028134503270333896, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:42,457] Trial 11 finished with value: 0.5949386303667529 and parameters: {'batch_size': 64, 'epochs': 80, 'n_hidden': 4, 'hidden_units': 128, 'dropout': 0.3440881592810015, 'lr': 0.0005427201661836973, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:52,850] Trial 12 finished with value: 0.5700343060566165 and parameters: {'batch_size': 64, 'epochs': 60, 'n_hidden': 4, 'hidden_units': 320, 'dropout': 0.3932527649964095, 'lr': 0.0003601866958432956, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:22:59,229] Trial 13 finished with value: 0.5968339914727752 and parameters: {'batch_size': 32, 'epochs': 70, 'n_hidden': 4, 'hidden_units': 128, 'dropout': 0.41408600230709797, 'lr': 0.0009950572385313495, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:23:13,525] Trial 14 finished with value: 0.5749495667160508 and parameters: {'batch_size': 64, 'epochs': 60, 'n_hidden': 3, 'hidden_units': 320, 'dropout': 0.2839381471590163, 'lr': 0.00010949583667048251, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:23:28,126] Trial 15 finished with value: 0.6149790158950464 and parameters: {'batch_size': 32, 'epochs': 80, 'n_hidden': 4, 'hidden_units': 128, 'dropout': 0.4191516913686134, 'lr': 0.0003690681399854023, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:23:32,409] Trial 16 finished with value: 0.5646554250246411 and parameters: {'batch_size': 64, 'epochs': 50, 'n_hidden': 2, 'hidden_units': 320, 'dropout': 0.2796310370234675, 'lr': 0.0014945627842673514, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:23:48,244] Trial 17 finished with value: 0.6161507063357403 and parameters: {'batch_size': 32, 'epochs': 70, 'n_hidden': 3, 'hidden_units': 256, 'dropout': 0.35747242165454507, 'lr': 0.00021614702372487976, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:24:00,112] Trial 18 finished with value: 0.6016091520048328 and parameters: {'batch_size': 32, 'epochs': 20, 'n_hidden': 3, 'hidden_units': 256, 'dropout': 0.45090178444966367, 'lr': 0.00017628785222764993, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:24:15,130] Trial 19 finished with value: 0.6021928704013002 and parameters: {'batch_size': 32, 'epochs': 60, 'n_hidden': 3, 'hidden_units': 448, 'dropout': 0.3759610619828418, 'lr': 0.0002690664312424564, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:24:34,100] Trial 20 finished with value: 0.5731122292389416 and parameters: {'batch_size': 32, 'epochs': 80, 'n_hidden': 2, 'hidden_units': 256, 'dropout': 0.2580864249944482, 'lr': 0.00013338754699511376, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:24:42,622] Trial 21 finished with value: 0.6017296869575046 and parameters: {'batch_size': 32, 'epochs': 70, 'n_hidden': 4, 'hidden_units': 192, 'dropout': 0.3372322087755712, 'lr': 0.0005664389574100558, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:24:51,356] Trial 22 finished with value: 0.5748451802909065 and parameters: {'batch_size': 64, 'epochs': 70, 'n_hidden': 4, 'hidden_units': 128, 'dropout': 0.4522986868380614, 'lr': 0.00037333969216414326, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:24:56,700] Trial 23 finished with value: 0.5705400143232902 and parameters: {'batch_size': 128, 'epochs': 60, 'n_hidden': 3, 'hidden_units': 192, 'dropout': 0.30987881467207556, 'lr': 0.0007683786037218905, 'optimizer': 'adamw'}. Best is trial 2 with value: 0.6229240737732653.\n",
            "[I 2025-11-27 14:25:09,043] Trial 24 finished with value: 0.6068059089780092 and parameters: {'batch_size': 32, 'epochs': 70, 'n_hidden': 4, 'hidden_units': 256, 'dropout': 0.3658841102221264, 'lr': 0.0002343489036095018, 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.6229240737732653.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best macro F1: 0.6229\n",
            "Best params:\n",
            "  batch_size: 32\n",
            "  epochs: 70\n",
            "  n_hidden: 4\n",
            "  hidden_units: 128\n",
            "  dropout: 0.47671295725378376\n",
            "  lr: 0.0002714935065113107\n",
            "  optimizer: adamw\n",
            "Validation accuracy: 0.7415\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", study_name=\"nn_macro_f1\")\n",
        "study.optimize(objective, n_trials=25, timeout=3600)\n",
        "\n",
        "print(f\"Best macro F1: {study.best_value:.4f}\")\n",
        "print(\"Best params:\")\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"Validation accuracy: {study.best_trial.user_attrs['accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.53      0.62        17\n",
            "           1       0.75      0.55      0.63        44\n",
            "           2       0.69      0.75      0.72        61\n",
            "           3       0.63      0.73      0.68        66\n",
            "           4       0.91      0.91      0.91       195\n",
            "\n",
            "    accuracy                           0.80       383\n",
            "   macro avg       0.75      0.69      0.71       383\n",
            "weighted avg       0.80      0.80      0.79       383\n",
            "\n",
            "Saved submission to /Users/aaryan/Desktop/ML_multi_class/nn_submission.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>personality_cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1005</td>\n",
              "      <td>Cluster_E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>197</td>\n",
              "      <td>Cluster_C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2343</td>\n",
              "      <td>Cluster_E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1709</td>\n",
              "      <td>Cluster_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>436</td>\n",
              "      <td>Cluster_E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   participant_id personality_cluster\n",
              "0            1005           Cluster_E\n",
              "1             197           Cluster_C\n",
              "2            2343           Cluster_E\n",
              "3            1709           Cluster_B\n",
              "4             436           Cluster_E"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params = study.best_trial.params.copy()\n",
        "\n",
        "combined_X = np.vstack([X_train, X_val])\n",
        "combined_y = np.concatenate([y_train, y_val])\n",
        "\n",
        "fixed_trial = optuna.trial.FixedTrial(best_params)\n",
        "best_model = build_model(fixed_trial)\n",
        "\n",
        "best_model.fit(\n",
        "    combined_X,\n",
        "    combined_y,\n",
        "    epochs=best_params[\"epochs\"],\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "val_preds = np.argmax(best_model.predict(X_val, verbose=0), axis=1)\n",
        "print(classification_report(y_val, val_preds))\n",
        "\n",
        "proba_test = best_model.predict(X_test, verbose=0)\n",
        "test_labels = np.argmax(proba_test, axis=1)\n",
        "\n",
        "submission = pd.DataFrame(\n",
        "    {\n",
        "        \"participant_id\": test_ids.squeeze(),\n",
        "        \"personality_cluster\": [encoded_to_cluster[int(label)] for label in test_labels],\n",
        "    }\n",
        ")\n",
        "\n",
        "nn_pred_path = OUTPUT_DIR / \"nn_submission.csv\"\n",
        "submission.to_csv(nn_pred_path, index=False)\n",
        "print(f\"Saved submission to {nn_pred_path}\")\n",
        "\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

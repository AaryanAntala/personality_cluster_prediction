{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# XGBoost Experiment with Optuna\n",
                "\n",
                "This notebook performs hyperparameter tuning for XGBoost using Optuna."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/aaryan/Desktop/ML_multi_class/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "import optuna\n",
                "from optuna.samplers import TPESampler\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "SEED = 42\n",
                "np.random.seed(SEED)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_advanced_features(df):\n",
                "    df = df.copy()\n",
                "    activity_cols = ['hobby_engagement_level', 'physical_activity_index', \n",
                "                     'creative_expression_index', 'altruism_score']\n",
                "    df['total_activity'] = df[activity_cols].sum(axis=1)\n",
                "    df['support_guidance_combo'] = df['support_environment_score'] * (df['external_guidance_usage'] + 1)\n",
                "    df['focus_efficiency'] = df['focus_intensity'] / (df['consistency_score'] + 1)\n",
                "    df['consistency_gap'] = 30 - df['consistency_score']\n",
                "    df['focus_sq'] = df['focus_intensity'] ** 2\n",
                "    df['focus_X_consistency'] = df['focus_intensity'] * df['consistency_score']\n",
                "    df['low_focus_high_consist'] = ((df['focus_intensity'] < 5) & (df['consistency_score'] > 24)).astype(int)\n",
                "    return df\n",
                "\n",
                "try:\n",
                "    train_df = pd.read_csv('./dataset/train.csv')\n",
                "    test_df = pd.read_csv('./dataset/test.csv')\n",
                "except FileNotFoundError:\n",
                "    print(\"❌ Upload train.csv and test.csv!\")\n",
                "\n",
                "train_df = create_advanced_features(train_df)\n",
                "test_df = create_advanced_features(test_df)\n",
                "\n",
                "X = train_df.drop(['participant_id', 'personality_cluster'], axis=1)\n",
                "y = train_df['personality_cluster']\n",
                "test_ids = test_df['participant_id']\n",
                "X_test = test_df.drop(['participant_id'], axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_cols = [\n",
                "    'identity_code', 'cultural_background', 'age_group', \n",
                "    'upbringing_influence', 'support_environment_score', \n",
                "    'hobby_engagement_level', 'physical_activity_index',\n",
                "    'creative_expression_index', 'altruism_score',\n",
                "    'low_focus_high_consist'\n",
                "]\n",
                "\n",
                "# Label Encoding for XGBoost\n",
                "for col in cat_cols:\n",
                "    le = LabelEncoder()\n",
                "    full_data = pd.concat([X[col], X_test[col]], axis=0).astype(str)\n",
                "    le.fit(full_data)\n",
                "    X[col] = le.transform(X[col].astype(str))\n",
                "    X_test[col] = le.transform(X_test[col].astype(str))\n",
                "\n",
                "# Scale Numerical Features (as per demo.py)\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "num_cols = [c for c in X.columns if c not in cat_cols]\n",
                "scaler = StandardScaler()\n",
                "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
                "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
                "\n",
                "target_le = LabelEncoder()\n",
                "y_encoded = target_le.fit_transform(y)\n",
                "num_classes = len(target_le.classes_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Optuna Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2025-11-27 18:01:29,976] A new study created in memory with name: no-name-56898d0c-7e0a-4ca8-9d08-67fc1b0a9fb9\n",
                        "[I 2025-11-27 18:01:42,881] Trial 0 finished with value: 0.5631908658383744 and parameters: {'n_estimators': 437, 'max_depth': 10, 'learning_rate': 0.06504856968981275, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'min_child_weight': 2, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469887}. Best is trial 0 with value: 0.5631908658383744.\n",
                        "[I 2025-11-27 18:02:01,975] Trial 1 finished with value: 0.5523027194376559 and parameters: {'n_estimators': 641, 'max_depth': 8, 'learning_rate': 0.001124579825911934, 'subsample': 0.9849549260809971, 'colsample_bytree': 0.9162213204002109, 'min_child_weight': 3, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: 0.5631908658383744.\n",
                        "[I 2025-11-27 18:02:12,031] Trial 2 finished with value: 0.5713274944229729 and parameters: {'n_estimators': 374, 'max_depth': 7, 'learning_rate': 0.01174843954800703, 'subsample': 0.645614570099021, 'colsample_bytree': 0.8059264473611898, 'min_child_weight': 2, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:02:32,474] Trial 3 finished with value: 0.5668657117352696 and parameters: {'n_estimators': 510, 'max_depth': 9, 'learning_rate': 0.003123317753376431, 'subsample': 0.7571172192068059, 'colsample_bytree': 0.7962072844310213, 'min_child_weight': 1, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:02:36,508] Trial 4 finished with value: 0.566718521858368 and parameters: {'n_estimators': 158, 'max_depth': 10, 'learning_rate': 0.24659691172104828, 'subsample': 0.9041986740582306, 'colsample_bytree': 0.6523068845866853, 'min_child_weight': 1, 'reg_alpha': 0.01439120761572808, 'reg_lambda': 9.148975058772307e-05}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:02:41,893] Trial 5 finished with value: 0.3078383164530159 and parameters: {'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.0012167028814593455, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085, 'min_child_weight': 7, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:02:55,107] Trial 6 finished with value: 0.5384492173867711 and parameters: {'n_estimators': 592, 'max_depth': 4, 'learning_rate': 0.25221951700214296, 'subsample': 0.8875664116805573, 'colsample_bytree': 0.9697494707820946, 'min_child_weight': 9, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493887}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:02:58,690] Trial 7 finished with value: 0.21612487226802946 and parameters: {'n_estimators': 179, 'max_depth': 4, 'learning_rate': 0.001294295611551122, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6943386448447411, 'min_child_weight': 3, 'reg_alpha': 0.287499823474079, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:03:07,932] Trial 8 finished with value: 0.4855717531321033 and parameters: {'n_estimators': 353, 'max_depth': 7, 'learning_rate': 0.0022340165853190056, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'min_child_weight': 10, 'reg_alpha': 0.08916674715636552, 'reg_lambda': 6.143857495033091e-07}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:03:12,106] Trial 9 finished with value: 0.5649048302537544 and parameters: {'n_estimators': 104, 'max_depth': 9, 'learning_rate': 0.0563600475052774, 'subsample': 0.8645035840204937, 'colsample_bytree': 0.8856351733429728, 'min_child_weight': 1, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:03:27,991] Trial 10 finished with value: 0.5435044528577813 and parameters: {'n_estimators': 880, 'max_depth': 6, 'learning_rate': 0.008191923351508625, 'subsample': 0.5089809378074098, 'colsample_bytree': 0.7846562513261506, 'min_child_weight': 5, 'reg_alpha': 4.3444691085504035, 'reg_lambda': 0.010039786460205658}. Best is trial 2 with value: 0.5713274944229729.\n",
                        "[I 2025-11-27 18:03:48,579] Trial 11 finished with value: 0.5755538564503296 and parameters: {'n_estimators': 751, 'max_depth': 8, 'learning_rate': 0.006081578518942674, 'subsample': 0.668335762954705, 'colsample_bytree': 0.7930679183446125, 'min_child_weight': 5, 'reg_alpha': 0.00017964951948595568, 'reg_lambda': 1.4959570499682912e-08}. Best is trial 11 with value: 0.5755538564503296.\n",
                        "[I 2025-11-27 18:04:17,810] Trial 12 finished with value: 0.5716846529320945 and parameters: {'n_estimators': 766, 'max_depth': 7, 'learning_rate': 0.009855966758712472, 'subsample': 0.642084951685628, 'colsample_bytree': 0.8265015800721067, 'min_child_weight': 5, 'reg_alpha': 6.957931273837839e-05, 'reg_lambda': 0.0074839487022762075}. Best is trial 11 with value: 0.5755538564503296.\n",
                        "[I 2025-11-27 18:04:40,739] Trial 13 finished with value: 0.5761439236538158 and parameters: {'n_estimators': 815, 'max_depth': 5, 'learning_rate': 0.006446852098048459, 'subsample': 0.6135695058254393, 'colsample_bytree': 0.7305508677576656, 'min_child_weight': 6, 'reg_alpha': 8.773472263092513e-05, 'reg_lambda': 0.016756638283609338}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:04:57,468] Trial 14 finished with value: 0.5651435651344919 and parameters: {'n_estimators': 924, 'max_depth': 5, 'learning_rate': 0.004958509019173871, 'subsample': 0.5559880584990722, 'colsample_bytree': 0.719593784688761, 'min_child_weight': 7, 'reg_alpha': 0.0003393258354765485, 'reg_lambda': 0.04394253214905646}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:05:05,546] Trial 15 finished with value: 0.5632618929256565 and parameters: {'n_estimators': 749, 'max_depth': 3, 'learning_rate': 0.02888608223459208, 'subsample': 0.6999903496918575, 'colsample_bytree': 0.7361609808336007, 'min_child_weight': 7, 'reg_alpha': 0.0004744231101925193, 'reg_lambda': 1.0705218842679536e-08}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:05:17,837] Trial 16 finished with value: 0.5605730109868836 and parameters: {'n_estimators': 764, 'max_depth': 5, 'learning_rate': 0.025397435009708508, 'subsample': 0.5842100973094366, 'colsample_bytree': 0.8601591101459543, 'min_child_weight': 6, 'reg_alpha': 1.1032173338053777e-08, 'reg_lambda': 0.0008602034987552218}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:05:42,815] Trial 17 finished with value: 0.5729653294358049 and parameters: {'n_estimators': 985, 'max_depth': 8, 'learning_rate': 0.004785794242955681, 'subsample': 0.7277598512385937, 'colsample_bytree': 0.6553447098489982, 'min_child_weight': 4, 'reg_alpha': 1.9890471217176365e-07, 'reg_lambda': 0.09438696640987573}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:05:56,472] Trial 18 finished with value: 0.5621669462408306 and parameters: {'n_estimators': 837, 'max_depth': 5, 'learning_rate': 0.017620109857567425, 'subsample': 0.5933722264278647, 'colsample_bytree': 0.991993515272915, 'min_child_weight': 8, 'reg_alpha': 1.8213424611458932e-06, 'reg_lambda': 6.601873053524983}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:06:14,480] Trial 19 finished with value: 0.5740699252021656 and parameters: {'n_estimators': 685, 'max_depth': 8, 'learning_rate': 0.0053942390836841814, 'subsample': 0.8020781426690895, 'colsample_bytree': 0.7544572512626753, 'min_child_weight': 6, 'reg_alpha': 5.5374021608806624e-05, 'reg_lambda': 0.0031003438944028137}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:06:24,689] Trial 20 finished with value: 0.5520481157517493 and parameters: {'n_estimators': 836, 'max_depth': 3, 'learning_rate': 0.002918546143175513, 'subsample': 0.5217668648940332, 'colsample_bytree': 0.9292066062055611, 'min_child_weight': 4, 'reg_alpha': 0.0030713580662157874, 'reg_lambda': 3.959627457035533e-06}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:06:41,671] Trial 21 finished with value: 0.5710763857895373 and parameters: {'n_estimators': 669, 'max_depth': 8, 'learning_rate': 0.005228033467404517, 'subsample': 0.7967081324025389, 'colsample_bytree': 0.7594126937433104, 'min_child_weight': 6, 'reg_alpha': 6.101830827538915e-05, 'reg_lambda': 0.0013029357082744127}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:07:01,264] Trial 22 finished with value: 0.575389759551772 and parameters: {'n_estimators': 682, 'max_depth': 9, 'learning_rate': 0.007170430573448087, 'subsample': 0.8149271154876796, 'colsample_bytree': 0.6959571301566982, 'min_child_weight': 5, 'reg_alpha': 6.932465996789345e-05, 'reg_lambda': 0.005756701997153493}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:07:15,719] Trial 23 finished with value: 0.569323872318869 and parameters: {'n_estimators': 531, 'max_depth': 9, 'learning_rate': 0.014195881147343634, 'subsample': 0.7086335388265667, 'colsample_bytree': 0.6948027687270727, 'min_child_weight': 4, 'reg_alpha': 0.00042012254345493436, 'reg_lambda': 0.11873432633415154}. Best is trial 13 with value: 0.5761439236538158.\n",
                        "[I 2025-11-27 18:07:33,469] Trial 24 finished with value: 0.5784251483166238 and parameters: {'n_estimators': 708, 'max_depth': 9, 'learning_rate': 0.007967225414701476, 'subsample': 0.6183051824215566, 'colsample_bytree': 0.5942586002997777, 'min_child_weight': 5, 'reg_alpha': 1.982316621457163e-05, 'reg_lambda': 0.024010129635236837}. Best is trial 24 with value: 0.5784251483166238.\n",
                        "[I 2025-11-27 18:07:52,491] Trial 25 finished with value: 0.49817902271116016 and parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.002208862652908637, 'subsample': 0.6109015403353707, 'colsample_bytree': 0.5071969601466384, 'min_child_weight': 8, 'reg_alpha': 8.248331500575923e-07, 'reg_lambda': 0.3613392983966395}. Best is trial 24 with value: 0.5784251483166238.\n",
                        "[I 2025-11-27 18:08:13,391] Trial 26 finished with value: 0.5751256764525154 and parameters: {'n_estimators': 758, 'max_depth': 10, 'learning_rate': 0.021169728578059304, 'subsample': 0.6763440643523563, 'colsample_bytree': 0.5988999699973716, 'min_child_weight': 5, 'reg_alpha': 9.081848370239373e-06, 'reg_lambda': 6.86057319080273e-05}. Best is trial 24 with value: 0.5784251483166238.\n",
                        "[I 2025-11-27 18:08:26,214] Trial 27 finished with value: 0.5608244496717618 and parameters: {'n_estimators': 841, 'max_depth': 4, 'learning_rate': 0.04813803845839739, 'subsample': 0.6241553111949505, 'colsample_bytree': 0.8364173367413743, 'min_child_weight': 4, 'reg_alpha': 0.021864532880591387, 'reg_lambda': 0.03104822366371355}. Best is trial 24 with value: 0.5784251483166238.\n",
                        "[I 2025-11-27 18:08:44,488] Trial 28 finished with value: 0.5274779915633511 and parameters: {'n_estimators': 607, 'max_depth': 7, 'learning_rate': 0.003460821052104396, 'subsample': 0.5570338131737974, 'colsample_bytree': 0.5666141074478376, 'min_child_weight': 6, 'reg_alpha': 1.3726750181314477e-07, 'reg_lambda': 1.6902749588425184e-08}. Best is trial 24 with value: 0.5784251483166238.\n",
                        "[I 2025-11-27 18:08:57,325] Trial 29 finished with value: 0.5526733191987989 and parameters: {'n_estimators': 475, 'max_depth': 10, 'learning_rate': 0.01224055866873207, 'subsample': 0.5456725945799329, 'colsample_bytree': 0.5984039417923832, 'min_child_weight': 8, 'reg_alpha': 2.6894368349353844e-05, 'reg_lambda': 0.8539407717707199}. Best is trial 24 with value: 0.5784251483166238.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best params: {'n_estimators': 708, 'max_depth': 9, 'learning_rate': 0.007967225414701476, 'subsample': 0.6183051824215566, 'colsample_bytree': 0.5942586002997777, 'min_child_weight': 5, 'reg_alpha': 1.982316621457163e-05, 'reg_lambda': 0.024010129635236837}\n"
                    ]
                }
            ],
            "source": [
                "def objective(trial):\n",
                "    params = {\n",
                "        'objective': 'multi:softmax',\n",
                "        'num_class': num_classes,\n",
                "        'tree_method': 'hist',\n",
                "        'eval_metric': 'mlogloss',\n",
                "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
                "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
                "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
                "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
                "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
                "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
                "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
                "        'random_state': SEED,\n",
                "        'n_jobs': -1\n",
                "    }\n",
                "    \n",
                "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
                "    scores = []\n",
                "    \n",
                "    for train_idx, val_idx in skf.split(X, y_encoded):\n",
                "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
                "        y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
                "        \n",
                "        model = xgb.XGBClassifier(**params)\n",
                "        model.fit(X_train_fold, y_train_fold)\n",
                "        \n",
                "        preds = model.predict(X_val_fold)\n",
                "        scores.append(f1_score(y_val_fold, preds, average='macro'))\n",
                "        \n",
                "    return np.mean(scores)\n",
                "\n",
                "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=SEED))\n",
                "study.optimize(objective, n_trials=30)\n",
                "\n",
                "print(\"Best params:\", study.best_params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Training & Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Saved submission_xgboost.csv\n"
                    ]
                }
            ],
            "source": [
                "best_params = study.best_params\n",
                "best_params.update({\n",
                "    'objective': 'multi:softmax',\n",
                "    'num_class': num_classes,\n",
                "    'tree_method': 'hist',\n",
                "    'eval_metric': 'mlogloss',\n",
                "    'random_state': SEED,\n",
                "    'n_jobs': -1\n",
                "})\n",
                "\n",
                "final_model = xgb.XGBClassifier(**best_params)\n",
                "final_model.fit(X, y_encoded)\n",
                "\n",
                "test_preds = final_model.predict(X_test)\n",
                "final_labels = target_le.inverse_transform(test_preds)\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'participant_id': test_ids,\n",
                "    'personality_cluster': final_labels\n",
                "})\n",
                "submission.to_csv('submission_xgboost.csv', index=False)\n",
                "print(\"✅ Saved submission_xgboost.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
